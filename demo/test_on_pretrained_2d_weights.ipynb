{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20455,"status":"ok","timestamp":1739138286795,"user":{"displayName":"Xu Zhang","userId":"14656563410696356313"},"user_tz":300},"id":"T-ah4BtXL3Ee","outputId":"372cd577-f9db-4807-82f1-5dbd5af1c2e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1121,"status":"ok","timestamp":1739138287913,"user":{"displayName":"Xu Zhang","userId":"14656563410696356313"},"user_tz":300},"id":"kTkMGuVSL5oI","outputId":"ceca7824-4154-43ec-ba1a-bca00e3cfdfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Reimplementation/MViT/mvit\n"]}],"source":["cd /content/drive/MyDrive/Reimplementation/MViT/mvit/"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"HKliUdqeL5q_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739138288122,"user_tz":300,"elapsed":208,"user":{"displayName":"Xu Zhang","userId":"14656563410696356313"}},"outputId":"0fd266e8-537c-4029-f4bc-61e9dcf30cb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Feb  9 21:57:55 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Koq7OxBxL5uA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739138383057,"user_tz":300,"elapsed":94933,"user":{"displayName":"Xu Zhang","userId":"14656563410696356313"}},"outputId":"3ba5b4fb-56d1-44cf-eee6-33d48bda2a70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting fairscale\n","  Downloading fairscale-0.4.13.tar.gz (266 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting simplejson\n","  Downloading simplejson-3.19.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (1.26.4)\n","Collecting yacs>=0.1.6 (from fvcore)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.5.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.1.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n","Collecting iopath>=0.1.7 (from fvcore)\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from fairscale) (2.5.1+cu124)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.12.2)\n","Collecting portalocker (from iopath>=0.1.7->fvcore)\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->fairscale)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->fairscale)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->fairscale)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->fairscale)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->fairscale)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->fairscale)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->fairscale)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->fairscale)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->fairscale)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->fairscale)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->fairscale) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->fairscale) (3.0.2)\n","Downloading simplejson-3.19.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: fvcore, fairscale, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=7e1832a8c05638815ce5ea0877580d7aaed1099da7b468d43f9e0a8b16a5d242\n","  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n","  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332156 sha256=79a7f3fcbe2372c8232cfada576936468b11b4932808a06d55ca297170ffd321\n","  Stored in directory: /root/.cache/pip/wheels/95/ef/96/5044bde220b2ea299bdc6ec05051e0ef187fad45b341d1c273\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=833cff941dd49521a4f87a7f447ddf1354a39745e08942c8a2d83aff053ce160\n","  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n","Successfully built fvcore fairscale iopath\n","Installing collected packages: yacs, simplejson, portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, nvidia-cusolver-cu12, fvcore, fairscale\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed fairscale-0.4.13 fvcore-0.1.5.post20221221 iopath-0.1.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 portalocker-3.1.1 simplejson-3.19.3 yacs-0.1.8\n"]}],"source":["pip install fvcore fairscale simplejson psutil"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"hU1sytkZRs3R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739138386795,"user_tz":300,"elapsed":3732,"user":{"displayName":"Xu Zhang","userId":"14656563410696356313"}},"outputId":"b5d291ac-c90f-42bb-93a8-9d4f94a02613"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (0.1.10)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath) (4.67.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath) (4.12.2)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath) (3.1.1)\n"]}],"source":["pip install -U iopath"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"zrmTbZ12R9Q5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739138386905,"user_tz":300,"elapsed":108,"user":{"displayName":"Xu Zhang","userId":"14656563410696356313"}},"outputId":"225dccde-2a92-45ba-bf11-1a9dc3e5c476"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mcheck_points\u001b[0m/       \u001b[01;34mconfigs\u001b[0m/         INSTALL.md  linter.sh  README.md  setup.py  \u001b[01;34mtools\u001b[0m/\n","CODE_OF_CONDUCT.md  CONTRIBUTING.md  LICENSE     \u001b[01;34mmvit\u001b[0m/      setup.cfg  \u001b[01;34mtmp\u001b[0m/\n"]}],"source":["ls\n"]},{"cell_type":"code","source":["!python tools/main.py \\\n","  --cfg /content/drive/MyDrive/Reimplementation/MViT/mvit/configs/test/MVITv2_T_test_on_pretrained_2d_weights.yaml \\\n","  DATA.PATH_TO_DATA_DIR /content/drive/MyDrive/Reimplementation/MViT/Imagenet1k \\\n","  NUM_GPUS 1 \\\n","  TEST.BATCH_SIZE 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iL-URoRPmj2Z","executionInfo":{"status":"ok","timestamp":1739138469557,"user_tz":300,"elapsed":82651,"user":{"displayName":"Xu Zhang","userId":"14656563410696356313"}},"outputId":"d82e8aed-bccd-4a49-b7e0-17629187d078"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[02/09 22:00:16][INFO] engine.py: 334: Test with config:\n","[02/09 22:00:18][INFO] engine.py: 335: CfgNode({'TRAIN': CfgNode({'ENABLE': False, 'DATASET': 'imagenet', 'BATCH_SIZE': 256, 'EVAL_PERIOD': 10, 'CHECKPOINT_PERIOD': 10, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_EPOCH_RESET': False, 'MIXED_PRECISION': False}), 'AUG': CfgNode({'NUM_SAMPLE': 1, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m9-n6-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.25, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False}), 'MIXUP': CfgNode({'ENABLE': True, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'imagenet', 'BATCH_SIZE': 2, 'CHECKPOINT_FILE_PATH': '/content/drive/MyDrive/Reimplementation/MViT/mvit/check_points/MViTv2_T_in1k.pyth', 'CHECKPOINT_SQUEEZE_TEMPORAL': True}), 'MODEL': CfgNode({'MODEL_NAME': 'MViT', 'NUM_CLASSES': 1000, 'LOSS_FUNC': 'soft_cross_entropy', 'DROPOUT_RATE': 0.0, 'HEAD_ACT': 'softmax', 'ACT_CHECKPOINT': False}), 'MVIT': CfgNode({'MODE': 'conv', 'POOL_FIRST': False, 'CLS_EMBED_ON': False, 'PATCH_KERNEL': [1, 7, 7], 'PATCH_STRIDE': [1, 4, 4], 'PATCH_PADDING': [1, 3, 3], 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.1, 'DEPTH': 10, 'DIM_MUL': [[1, 2.0], [3, 2.0], [8, 2.0]], 'HEAD_MUL': [[1, 2.0], [3, 2.0], [8, 2.0]], 'POOL_KV_STRIDE': None, 'POOL_KV_STRIDE_ADAPTIVE': [1, 4, 4], 'POOL_Q_STRIDE': [[0, 1, 1, 1], [1, 1, 2, 2], [2, 1, 1, 1], [3, 1, 2, 2], [4, 1, 1, 1], [5, 1, 1, 1], [6, 1, 1, 1], [7, 1, 1, 1], [8, 1, 2, 2], [9, 1, 1, 1]], 'POOL_KVQ_KERNEL': (1, 3, 3), 'ZERO_DECAY_POS_CLS': False, 'USE_ABS_POS': False, 'REL_POS_SPATIAL': True, 'REL_POS_ZERO_INIT': False, 'RESIDUAL_POOLING': True, 'DIM_MUL_IN_ATT': True}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/content/drive/MyDrive/Reimplementation/MViT/Imagenet1k', 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.485, 0.456, 0.406], 'STD': [0.229, 0.224, 0.225], 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'VAL_CROP_RATIO': 0.875, 'IN22K_TRAINVAL': False, 'IN22k_VAL_IN1K': ''}), 'SOLVER': CfgNode({'BASE_LR': 0.00025, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 310, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 70.0, 'WARMUP_START_LR': 1e-08, 'OPTIMIZING_METHOD': 'sgd', 'BASE_LR_SCALE_NUM_SHARDS': False, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRAD_VAL': None, 'CLIP_GRAD_L2NORM': None, 'LAYER_DECAY': 1.0}), 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': './tmp', 'RNG_SEED': 0, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'DATA_LOADER': CfgNode({'NUM_WORKERS': 8, 'PIN_MEMORY': True})})\n","[02/09 22:00:19][INFO] checkpoint.py: 153: Loading network weights from /content/drive/MyDrive/Reimplementation/MViT/mvit/check_points/MViTv2_T_in1k.pyth.\n","/content/drive/MyDrive/Reimplementation/MViT/mvit/mvit/utils/checkpoint.py:160: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(f, map_location=\"cpu\")\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.0.attn.rel_pos_h not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.0.attn.rel_pos_w not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.1.attn.rel_pos_h not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.1.attn.rel_pos_w not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.2.attn.rel_pos_h not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.2.attn.rel_pos_w not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.3.attn.rel_pos_h not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.3.attn.rel_pos_w not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.4.attn.rel_pos_h not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.4.attn.rel_pos_w not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.5.attn.rel_pos_h not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.5.attn.rel_pos_w not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.6.attn.rel_pos_h not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.6.attn.rel_pos_w not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.7.attn.rel_pos_h not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.7.attn.rel_pos_w not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.8.attn.rel_pos_h not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.8.attn.rel_pos_w not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.9.attn.rel_pos_h not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 199: Network weights blocks.9.attn.rel_pos_w not loaded.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.0.attn.rel_pos_h not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.0.attn.rel_pos_w not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.1.attn.rel_pos_h not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.1.attn.rel_pos_w not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.2.attn.rel_pos_h not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.2.attn.rel_pos_w not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.3.attn.rel_pos_h not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.3.attn.rel_pos_w not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.4.attn.rel_pos_h not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.4.attn.rel_pos_w not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.5.attn.rel_pos_h not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.5.attn.rel_pos_w not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.6.attn.rel_pos_h not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.6.attn.rel_pos_w not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.7.attn.rel_pos_h not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.7.attn.rel_pos_w not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.8.attn.rel_pos_h not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.8.attn.rel_pos_w not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.9.attn.rel_pos_h not used.\n","[02/09 22:00:29][INFO] checkpoint.py: 207: Network weights blocks.9.attn.rel_pos_w not used.\n","[02/09 22:00:29][INFO] imagenet.py:  35: Constructing ImageNet test...\n","[02/09 22:00:29][INFO] imagenet.py:  54: test data path: /content/drive/MyDrive/Reimplementation/MViT/Imagenet1k/test\n","[02/09 22:00:30][INFO] imagenet.py:  68: Number of images: 203\n","[02/09 22:00:30][INFO] imagenet.py:  69: Number of classes: 4\n","/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","[02/09 22:00:30][INFO] engine.py: 346: Testing model for 102 iterations\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[02/09 22:00:34][INFO] logging.py:  95: json_stats: {\"_type\": \"val_iter\", \"epoch\": \"0/310\", \"eta\": \"0:00:22\", \"gpu_mem\": \"0.46G\", \"iter\": \"10/102\", \"time_diff\": 0.23940, \"top1_err\": 100.00000, \"top5_err\": 50.00000}\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[02/09 22:00:36][INFO] logging.py:  95: json_stats: {\"_type\": \"val_iter\", \"epoch\": \"0/310\", \"eta\": \"0:00:04\", \"gpu_mem\": \"0.46G\", \"iter\": \"20/102\", \"time_diff\": 0.05164, \"top1_err\": 100.00000, \"top5_err\": 100.00000}\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[02/09 22:00:38][INFO] logging.py:  95: json_stats: {\"_type\": \"val_iter\", \"epoch\": \"0/310\", \"eta\": \"0:00:03\", \"gpu_mem\": \"0.46G\", \"iter\": \"30/102\", \"time_diff\": 0.05121, \"top1_err\": 50.00000, \"top5_err\": 25.00000}\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[02/09 22:00:40][INFO] logging.py:  95: json_stats: {\"_type\": \"val_iter\", \"epoch\": \"0/310\", \"eta\": \"0:00:03\", \"gpu_mem\": \"0.46G\", \"iter\": \"40/102\", \"time_diff\": 0.05064, \"top1_err\": 0.00000, \"top5_err\": 0.00000}\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[02/09 22:00:43][INFO] logging.py:  95: json_stats: {\"_type\": \"val_iter\", \"epoch\": \"0/310\", \"eta\": \"0:00:02\", \"gpu_mem\": \"0.46G\", \"iter\": \"50/102\", \"time_diff\": 0.05329, \"top1_err\": 0.00000, \"top5_err\": 0.00000}\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[02/09 22:00:46][INFO] logging.py:  95: json_stats: {\"_type\": \"val_iter\", \"epoch\": \"0/310\", \"eta\": \"0:00:02\", \"gpu_mem\": \"0.46G\", \"iter\": \"60/102\", \"time_diff\": 0.06113, \"top1_err\": 75.00000, \"top5_err\": 25.00000}\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[02/09 22:00:47][INFO] logging.py:  95: json_stats: {\"_type\": \"val_iter\", \"epoch\": \"0/310\", \"eta\": \"0:00:01\", \"gpu_mem\": \"0.46G\", \"iter\": \"70/102\", \"time_diff\": 0.05208, \"top1_err\": 100.00000, \"top5_err\": 25.00000}\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[02/09 22:00:49][INFO] logging.py:  95: json_stats: {\"_type\": \"val_iter\", \"epoch\": \"0/310\", \"eta\": \"0:00:01\", \"gpu_mem\": \"0.46G\", \"iter\": \"80/102\", \"time_diff\": 0.05789, \"top1_err\": 100.00000, \"top5_err\": 0.00000}\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[02/09 22:00:52][INFO] logging.py:  95: json_stats: {\"_type\": \"val_iter\", \"epoch\": \"0/310\", \"eta\": \"0:00:00\", \"gpu_mem\": \"0.46G\", \"iter\": \"90/102\", \"time_diff\": 0.05528, \"top1_err\": 50.00000, \"top5_err\": 0.00000}\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","[02/09 22:00:55][INFO] logging.py:  95: json_stats: {\"_type\": \"val_iter\", \"epoch\": \"0/310\", \"eta\": \"0:00:00\", \"gpu_mem\": \"0.46G\", \"iter\": \"100/102\", \"time_diff\": 0.05194, \"top1_err\": 50.00000, \"top5_err\": 0.00000}\n","\n","\n","\n","\n","[02/09 22:00:55][INFO] logging.py:  95: json_stats: {\"RAM\": \"1.98/12.67G\", \"_type\": \"val_epoch\", \"epoch\": \"0/310\", \"gpu_mem\": \"0.46G\", \"min_top1_err\": 55.88235, \"min_top5_err\": 25.49020, \"time_diff\": 0.07053, \"top1_err\": 55.88235, \"top5_err\": 25.49020}\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyP/uX++Bu6QrVvs59on4VCH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}